name: Deploy to EKS

# Builds images, pushes to ECR, and deploys to EKS (us-west-2)
# Manual trigger only for production safety

on:
  workflow_dispatch:
    inputs:
      services:
        description: 'Services to build and deploy'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - agent
          - ai-pipeline
          - config-service
          - k8s-gateway
          - knowledge-base
          - orchestrator
          - ultimate-rag
          - web-ui
      skip_deploy:
        description: 'Skip Helm deployment (build & push only)'
        required: false
        default: false
        type: boolean

env:
  AWS_REGION: us-west-2
  ECR_REGISTRY: 103002841599.dkr.ecr.us-west-2.amazonaws.com
  EKS_CLUSTER: incidentfox-demo
  HELM_NAMESPACE: incidentfox

jobs:
  build-and-push:
    name: Build & Push ${{ matrix.service }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        service: [agent, ai-pipeline, config-service, k8s-gateway, knowledge-base, orchestrator, ultimate-rag, web-ui]
        include:
          - service: agent
            context: ./agent
            dockerfile: ./agent/Dockerfile
            image: incidentfox-agent
          - service: ai-pipeline
            context: ./ai_pipeline
            dockerfile: ./ai_pipeline/Dockerfile
            image: incidentfox-ai-pipeline
          - service: config-service
            context: ./config_service
            dockerfile: ./config_service/Dockerfile
            image: incidentfox-config-service
          - service: k8s-gateway
            context: ./k8s_gateway
            dockerfile: ./k8s_gateway/Dockerfile
            image: incidentfox-k8s-gateway
          - service: knowledge-base
            context: ./knowledge_base
            dockerfile: ./knowledge_base/Dockerfile
            image: incidentfox-knowledge-base
          - service: orchestrator
            context: ./orchestrator
            dockerfile: ./orchestrator/Dockerfile
            image: incidentfox-orchestrator
          - service: ultimate-rag
            context: .
            dockerfile: ./ultimate_rag/Dockerfile
            image: incidentfox-ultimate-rag
          - service: web-ui
            context: ./web_ui
            dockerfile: ./web_ui/Dockerfile
            image: incidentfox-web-ui

    steps:
      - name: Check if service should be built
        id: should-build
        run: |
          if [ "${{ github.event.inputs.services }}" = "all" ] || [ "${{ github.event.inputs.services }}" = "${{ matrix.service }}" ]; then
            echo "build=true" >> $GITHUB_OUTPUT
          else
            echo "build=false" >> $GITHUB_OUTPUT
          fi

      - name: Checkout code
        if: steps.should-build.outputs.build == 'true'
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        if: steps.should-build.outputs.build == 'true'
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        if: steps.should-build.outputs.build == 'true'
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Set up Docker Buildx
        if: steps.should-build.outputs.build == 'true'
        uses: docker/setup-buildx-action@v3

      - name: Build and push to ECR
        if: steps.should-build.outputs.build == 'true'
        id: build
        uses: docker/build-push-action@v5
        with:
          context: ${{ matrix.context }}
          file: ${{ matrix.dockerfile }}
          platforms: linux/amd64
          push: true
          tags: |
            ${{ env.ECR_REGISTRY }}/${{ matrix.image }}:latest
            ${{ env.ECR_REGISTRY }}/${{ matrix.image }}:${{ github.sha }}
          cache-from: type=gha,scope=${{ matrix.service }}
          cache-to: type=gha,mode=max,scope=${{ matrix.service }}

      - name: Summary
        if: steps.should-build.outputs.build == 'true'
        run: |
          echo "## Built ${{ matrix.service }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Image**: \`${{ env.ECR_REGISTRY }}/${{ matrix.image }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Tags**: \`latest\`, \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Digest**: \`${{ steps.build.outputs.digest }}\`" >> $GITHUB_STEP_SUMMARY

  deploy:
    name: Deploy to EKS
    needs: build-and-push
    if: ${{ github.event.inputs.skip_deploy != 'true' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Show AWS identity (for aws-auth debugging)
        run: |
          echo "=== AWS Caller Identity ==="
          aws sts get-caller-identity
          echo ""
          echo "Add the above ARN to your EKS aws-auth ConfigMap if not already present"

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --name ${{ env.EKS_CLUSTER }} --region ${{ env.AWS_REGION }}

      - name: Verify cluster access
        run: |
          kubectl cluster-info
          kubectl get nodes

      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
          version: 'v3.14.0'

      - name: Adopt orphaned resources for Helm
        run: |
          # Fix resources that exist but weren't created by this Helm release
          # This adds required Helm ownership labels so Helm can manage them
          RESOURCE_NAME="incidentfox-knowledge-base"
          NS="${{ env.HELM_NAMESPACE }}"

          # Helper function to patch a resource with Helm ownership metadata
          patch_resource() {
            local kind=$1
            local name=$2
            if kubectl get "$kind" "$name" -n "$NS" &>/dev/null; then
              echo "Patching $kind/$name with Helm ownership labels..."
              kubectl label "$kind" "$name" -n "$NS" app.kubernetes.io/managed-by=Helm --overwrite
              kubectl annotate "$kind" "$name" -n "$NS" \
                meta.helm.sh/release-name=incidentfox \
                meta.helm.sh/release-namespace="$NS" --overwrite
            fi
          }

          # Patch all knowledge-base resources
          patch_resource serviceaccount "$RESOURCE_NAME"
          patch_resource service "$RESOURCE_NAME"
          patch_resource poddisruptionbudget "$RESOURCE_NAME"

          # Deployment selector is immutable - must delete and let Helm recreate
          if kubectl get deployment "$RESOURCE_NAME" -n "$NS" &>/dev/null; then
            echo "Deleting deployment/$RESOURCE_NAME (selector is immutable, Helm will recreate)..."
            kubectl delete deployment "$RESOURCE_NAME" -n "$NS" --wait=false
          fi

      - name: Deploy with Helm (no wait)
        working-directory: charts
        run: |
          # Deploy without --wait to avoid Helm's aggressive API polling
          # We'll use kubectl rollout status instead (more efficient, better errors)
          helm upgrade --install incidentfox ./incidentfox \
            -n ${{ env.HELM_NAMESPACE }} \
            -f incidentfox/values.prod.yaml \
            --no-hooks \
            --force \
            --timeout 5m

      - name: Restart deployments to pull latest images
        run: |
          # Helm upgrade with :latest tags doesn't restart pods even with imagePullPolicy: Always
          # because existing pods won't re-pull unless recreated.
          # Explicitly restart deployments that were built to force new image pulls.
          echo "Restarting deployments to pull latest images..."

          SERVICES="${{ github.event.inputs.services }}"
          NS="${{ env.HELM_NAMESPACE }}"

          restart_deployment() {
            local deploy=$1
            if kubectl get deployment "$deploy" -n "$NS" &>/dev/null; then
              echo "Restarting $deploy..."
              kubectl rollout restart deployment/"$deploy" -n "$NS"
            fi
          }

          if [ "$SERVICES" = "all" ]; then
            # Restart all deployments
            restart_deployment "incidentfox-config-service"
            restart_deployment "incidentfox-orchestrator"
            restart_deployment "incidentfox-agent"
            restart_deployment "incidentfox-web-ui"
            restart_deployment "incidentfox-k8s-gateway"
            restart_deployment "incidentfox-knowledge-base"
            restart_deployment "incidentfox-ultimate-rag"
            restart_deployment "incidentfox-ai-pipeline"
          else
            # Restart only the specific service
            case "$SERVICES" in
              agent) restart_deployment "incidentfox-agent" ;;
              ai-pipeline) restart_deployment "incidentfox-ai-pipeline" ;;
              config-service) restart_deployment "incidentfox-config-service" ;;
              k8s-gateway) restart_deployment "incidentfox-k8s-gateway" ;;
              knowledge-base) restart_deployment "incidentfox-knowledge-base" ;;
              orchestrator) restart_deployment "incidentfox-orchestrator" ;;
              ultimate-rag) restart_deployment "incidentfox-ultimate-rag" ;;
              web-ui) restart_deployment "incidentfox-web-ui" ;;
            esac
          fi

      - name: Wait for core services
        run: |
          echo "Waiting for core services to be ready..."
          # Core services should start quickly (1-2 min)
          kubectl rollout status deployment/incidentfox-config-service -n ${{ env.HELM_NAMESPACE }} --timeout=5m
          kubectl rollout status deployment/incidentfox-orchestrator -n ${{ env.HELM_NAMESPACE }} --timeout=5m
          kubectl rollout status deployment/incidentfox-agent -n ${{ env.HELM_NAMESPACE }} --timeout=5m
          kubectl rollout status deployment/incidentfox-web-ui -n ${{ env.HELM_NAMESPACE }} --timeout=5m

          # K8s Gateway (optional - only if enabled)
          if kubectl get deployment/incidentfox-k8s-gateway -n ${{ env.HELM_NAMESPACE }} &>/dev/null; then
            kubectl rollout status deployment/incidentfox-k8s-gateway -n ${{ env.HELM_NAMESPACE }} --timeout=5m
          fi

      - name: Wait for RAG services (slow startup)
        run: |
          echo "Waiting for RAG services (these download from S3 and load models)..."
          # RAG services need longer timeout (S3 download + model loading)
          # Run in parallel with background processes
          pids=()

          if kubectl get deployment/incidentfox-knowledge-base -n ${{ env.HELM_NAMESPACE }} &>/dev/null; then
            kubectl rollout status deployment/incidentfox-knowledge-base -n ${{ env.HELM_NAMESPACE }} --timeout=10m &
            pids+=($!)
          fi

          if kubectl get deployment/incidentfox-ultimate-rag -n ${{ env.HELM_NAMESPACE }} &>/dev/null; then
            kubectl rollout status deployment/incidentfox-ultimate-rag -n ${{ env.HELM_NAMESPACE }} --timeout=10m &
            pids+=($!)
          fi

          # Wait for all background processes
          failed=0
          for pid in "${pids[@]}"; do
            if ! wait $pid; then
              failed=1
            fi
          done

          if [ $failed -eq 1 ]; then
            echo "::warning::One or more RAG services failed to start. Checking pod status..."
            kubectl get pods -n ${{ env.HELM_NAMESPACE }} -l 'app.kubernetes.io/component in (knowledge-base, ultimate-rag)'
            kubectl describe pods -n ${{ env.HELM_NAMESPACE }} -l 'app.kubernetes.io/component in (knowledge-base, ultimate-rag)' | tail -100
            exit 1
          fi

      - name: Verify deployment
        run: |
          echo "## Deployment Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Pods" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          kubectl get pods -n ${{ env.HELM_NAMESPACE }} >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Image Digests" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          kubectl get pods -n ${{ env.HELM_NAMESPACE }} -o jsonpath='{range .items[*]}{.metadata.name}: {.status.containerStatuses[0].imageID}{"\n"}{end}' | grep -E "(agent|config-service|knowledge-base|orchestrator|web-ui|ultimate-rag)" >> $GITHUB_STEP_SUMMARY || true
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

      - name: Summary
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "**Deployed to**: \`${{ env.EKS_CLUSTER }}\` in \`${{ env.AWS_REGION }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Namespace**: \`${{ env.HELM_NAMESPACE }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
