# ============================================
# IncidentFox — Local Development Environment
# ============================================
# Copy to .env and fill in your values.
# Then run: make dev
#
# Required: ANTHROPIC_API_KEY (or whichever provider you use)
# Everything else is optional depending on what you want to test.

# ============================================
# Configuration Mode
# ============================================
# "local" enables YAML-based config from config_service/config/local.yaml.
# Hot-reload is on — edit the YAML file and changes apply without restart.
CONFIG_MODE=local

# ============================================
# AI Provider API Keys
# ============================================
# Set the key for whichever provider you configure in local.yaml.
# By default local.yaml uses Anthropic — only ANTHROPIC_API_KEY is needed.
#
# To switch providers, edit the ai_model section in local.yaml and
# add the corresponding key below.

# Anthropic (default — Claude models)
ANTHROPIC_API_KEY=sk-ant-your-api-key

# OpenAI (gpt-4o, gpt-4o-mini, o1, o3, o4-mini, ...)
#OPENAI_API_KEY=sk-your-openai-key

# Google Gemini (gemini-2.5-pro, gemini-2.5-flash, gemini-2.0-flash, ...)
#GEMINI_API_KEY=your-gemini-key

# DeepSeek (deepseek-chat, deepseek-reasoner, ...)
#DEEPSEEK_API_KEY=your-deepseek-key

# Mistral AI (mistral-large-latest, mistral-small-latest, codestral-latest, ...)
#MISTRAL_API_KEY=your-mistral-key

# xAI / Grok (grok-3, grok-3-beta, grok-2-latest, ...)
#XAI_API_KEY=your-xai-key

# Groq — fast hosted inference (llama-3.3-70b-versatile, llama-4-scout, ...)
#GROQ_API_KEY=gsk_your-groq-key

# Cohere (command-a-03-2025, command-r-plus, ...)
#COHERE_API_KEY=your-cohere-key

# OpenRouter — access 300+ models with one key (openrouter.ai/models)
#OPENROUTER_API_KEY=sk-or-your-openrouter-key

# Ollama — local models, no API key needed (configure base_url in local.yaml)

# AWS Bedrock — Claude, Llama, Mistral via AWS
#AWS_BEARER_TOKEN_BEDROCK=your-bedrock-bearer-token

# Azure AI Foundry — serverless model endpoints
#AZURE_AI_API_KEY=your-azure-ai-key
#AZURE_AI_API_BASE=https://your-endpoint.services.ai.azure.com

# ============================================
# Slack (required for Slack integration)
# ============================================
# See docs/SLACK_SETUP.md for how to create a Slack app and get these tokens.
# Without these, the slack-bot exits gracefully — other services still run.

# Bot Token from OAuth & Permissions
#SLACK_BOT_TOKEN=xoxb-your-bot-token

# App Token for Socket Mode (from Basic Information -> App-Level Tokens)
#SLACK_APP_TOKEN=xapp-your-app-token  # Socket Mode app-level token

# ============================================
# Config Service (defaults work out of the box)
# ============================================
# Only override these if you need custom values.
#TOKEN_PEPPER=localdev-pepper-must-be-32-chars-minimum!!
#ADMIN_TOKEN=local-admin-token

# ============================================
# Observability Integrations (optional)
# ============================================
# These match the integrations section in local.yaml.
# Add the key here, then uncomment the integration block in local.yaml.

#CORALOGIX_API_KEY=your-coralogix-key
#CORALOGIX_DOMAIN=https://yourteam.app.cx498.coralogix.com

#DATADOG_API_KEY=
#DATADOG_APP_KEY=

#GRAFANA_URL=
#GRAFANA_API_KEY=

#PROMETHEUS_URL=

#GITHUB_TOKEN=ghp_your-github-token

# ============================================
# AWS (optional — for CloudWatch, EKS, EC2 queries)
# ============================================
# Note: Also used for AWS Bedrock if AWS_BEARER_TOKEN_BEDROCK is not set.
#AWS_ACCESS_KEY_ID=your-access-key
#AWS_SECRET_ACCESS_KEY=your-secret-key
#AWS_REGION=us-west-2

# ============================================
# Tracing & Debug (optional)
# ============================================
#LMNR_PROJECT_API_KEY=lm_your-key  # Laminar tracing for agent behavior
#LOG_LEVEL=INFO
