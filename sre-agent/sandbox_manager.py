"""
Kubernetes Sandbox Manager

Manages isolated sandboxes for investigations using K8s agent-sandbox.
Follows the agent-sandbox pattern with FastAPI servers running on port 8888.

Security: Each sandbox gets a unique JWT embedded in its Envoy config.
The credential-resolver validates this JWT to ensure only legitimate
sandboxes can request credentials for their designated tenant/team.
"""

import json
import os
import time
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Optional

import requests
from auth import generate_sandbox_jwt
from kubernetes import client
from kubernetes import config as k8s_config
from kubernetes.client.rest import ApiException


def fetch_configured_integrations(jwt_token: str, tenant_id: str, team_id: str) -> str:
    """Fetch configured integrations from credential-resolver.

    This is called when creating a sandbox to inject integration metadata
    into the sandbox environment. The agent can then know what integrations
    are available without making runtime API calls.

    Args:
        jwt_token: JWT for authentication
        tenant_id: Tenant ID
        team_id: Team ID

    Returns:
        JSON string of integration metadata (non-sensitive)
    """
    cred_resolver_ns = os.getenv("CREDENTIAL_RESOLVER_NAMESPACE", "incidentfox-prod")

    # In local dev, use port-forwarded URL
    local_port = os.getenv("CREDENTIAL_RESOLVER_LOCAL_PORT")
    if local_port:
        url = f"http://localhost:{local_port}/api/integrations"
    else:
        url = f"http://credential-resolver-svc.{cred_resolver_ns}.svc.cluster.local:8002/api/integrations"

    headers = {
        "Accept": "application/json",
        "X-Sandbox-JWT": jwt_token,
        "X-Tenant-Id": tenant_id,
        "X-Team-Id": team_id,
    }

    try:
        response = requests.get(url, headers=headers, timeout=5)
        response.raise_for_status()
        data = response.json()
        # Return as compact JSON string for env var
        return json.dumps(data.get("integrations", []))
    except Exception as e:
        print(f"âš ï¸ Failed to fetch integrations: {e}")
        # Return empty list on failure - skills will handle gracefully
        return "[]"


class SandboxExecutionError(Exception):
    """Raised when sandbox execution fails."""

    pass


class SandboxInterruptError(Exception):
    """Raised when sandbox interrupt fails."""

    pass


@dataclass
class SandboxInfo:
    """Information about a running sandbox."""

    name: str
    thread_id: str
    created_at: datetime
    namespace: str = "default"


class SandboxManager:
    """Manage investigation sandboxes in Kubernetes."""

    def __init__(
        self, namespace: str = "default", image: str = "incidentfox-agent:latest"
    ):
        """
        Initialize sandbox manager.

        Args:
            namespace: Kubernetes namespace for sandboxes
            image: Docker image to use for sandboxes (defaults to local image,
                   use ECR URI for production: xxx.dkr.ecr.region.amazonaws.com/incidentfox-agent:latest)
        """
        self.namespace = namespace
        self.image = image
        self._load_k8s_config()
        self.custom_api = client.CustomObjectsApi()
        self.core_api = client.CoreV1Api()

    def _load_k8s_config(self):
        """Load Kubernetes configuration."""
        try:
            # Try in-cluster config first (when running in K8s)
            k8s_config.load_incluster_config()
        except:
            # Fall back to local kubeconfig (development)
            k8s_config.load_kube_config()

    def _create_envoy_configmap(
        self,
        sandbox_name: str,
        jwt_token: str,
    ) -> str:
        """Create a per-sandbox ConfigMap with JWT embedded in Envoy config.

        Each sandbox gets its own ConfigMap with the JWT as a static header.
        This ensures credential-resolver can cryptographically verify the
        sandbox identity and prevent credential theft via spoofed headers.

        Args:
            sandbox_name: Name of the sandbox (used for ConfigMap naming)
            jwt_token: JWT token to embed in the Envoy config

        Returns:
            Name of the created ConfigMap
        """
        configmap_name = f"envoy-config-{sandbox_name}"

        # Get credential-resolver namespace (where the service runs)
        cred_resolver_ns = os.getenv(
            "CREDENTIAL_RESOLVER_NAMESPACE", "incidentfox-prod"
        )

        envoy_config = f"""# Envoy proxy configuration for credential injection
# Per-sandbox config with embedded JWT for authentication
# Generated by SandboxManager - DO NOT EDIT

admin:
  address:
    socket_address:
      address: 127.0.0.1
      port_value: 9901

static_resources:
  listeners:
  - name: http_proxy
    address:
      socket_address:
        address: 0.0.0.0
        port_value: 8001
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: credential_proxy
          codec_type: AUTO

          http_protocol_options:
            allow_absolute_url: true

          route_config:
            name: proxy_routes
            virtual_hosts:
            # Localhost proxy mode (SDK uses BASE_URL=http://localhost:8001)
            - name: localhost_proxy
              domains:
              - "localhost:8001"
              - "127.0.0.1:8001"
              - "localhost"
              routes:
              # Anthropic API paths
              - match:
                  prefix: "/v1/"
                route:
                  cluster: anthropic
                  auto_host_rewrite: true
              - match:
                  prefix: "/api/event_logging/"
                route:
                  cluster: anthropic
                  auto_host_rewrite: true
              # Coralogix API paths
              - match:
                  prefix: "/api/v1/dataprime/"
                route:
                  cluster: coralogix_us2
                  auto_host_rewrite: true
              - match:
                  prefix: "/api/v1/query"
                route:
                  cluster: coralogix_us2
                  auto_host_rewrite: true

            # Direct host routing (for HTTP_PROXY mode if used)
            - name: anthropic
              domains:
              - "api.anthropic.com"
              - "api.anthropic.com:443"
              routes:
              - match:
                  prefix: "/"
                route:
                  cluster: anthropic
                  auto_host_rewrite: true

            - name: coralogix_us2
              domains:
              - "api.us2.coralogix.com"
              - "api.us2.coralogix.com:443"
              routes:
              - match:
                  prefix: "/"
                route:
                  cluster: coralogix_us2
                  auto_host_rewrite: true

            # Passthrough for unmapped domains
            - name: passthrough
              domains:
              - "*"
              routes:
              - match:
                  prefix: "/"
                route:
                  cluster: passthrough_cluster
                  auto_host_rewrite: true

          http_filters:
          # ext_authz filter - calls credential-resolver for auth headers
          - name: envoy.filters.http.ext_authz
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthz
              transport_api_version: V3
              http_service:
                server_uri:
                  uri: http://credential-resolver-svc.{cred_resolver_ns}.svc.cluster.local:8002/check
                  cluster: ext_authz
                  timeout: 2s
                authorization_request:
                  # Add JWT and target host as headers to ext_authz
                  headers_to_add:
                  - key: "x-sandbox-jwt"
                    value: "{jwt_token}"
                  - key: "x-original-host"
                    value: "%REQ(:authority)%"
                authorization_response:
                  # These headers from ext_authz response are added to upstream request
                  allowed_upstream_headers:
                    patterns:
                    - exact: "authorization"
                    - exact: "x-api-key"
              failure_mode_allow: false

          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router

  clusters:
  # ext_authz cluster (credential-resolver service)
  - name: ext_authz
    type: STRICT_DNS
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: ext_authz
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: credential-resolver-svc.{cred_resolver_ns}.svc.cluster.local
                port_value: 8002

  # Anthropic API
  - name: anthropic
    type: LOGICAL_DNS
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: anthropic
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: api.anthropic.com
                port_value: 443
    transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
        sni: api.anthropic.com

  # Coralogix US2
  - name: coralogix_us2
    type: LOGICAL_DNS
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: coralogix_us2
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: api.us2.coralogix.com
                port_value: 443
    transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
        sni: api.us2.coralogix.com

  # Passthrough cluster (placeholder)
  - name: passthrough_cluster
    type: LOGICAL_DNS
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: passthrough_cluster
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: localhost
                port_value: 9999
"""

        configmap = client.V1ConfigMap(
            api_version="v1",
            kind="ConfigMap",
            metadata=client.V1ObjectMeta(
                name=configmap_name,
                namespace=self.namespace,
                labels={
                    "app": "incidentfox",
                    "component": "envoy-config",
                    "sandbox": sandbox_name,
                },
            ),
            data={"envoy.yaml": envoy_config},
        )

        try:
            self.core_api.create_namespaced_config_map(
                namespace=self.namespace, body=configmap
            )
        except ApiException as e:
            if e.status == 409:
                # ConfigMap already exists, update it
                self.core_api.replace_namespaced_config_map(
                    name=configmap_name, namespace=self.namespace, body=configmap
                )
            else:
                raise

        return configmap_name

    def _delete_envoy_configmap(self, sandbox_name: str):
        """Delete the per-sandbox Envoy ConfigMap."""
        configmap_name = f"envoy-config-{sandbox_name}"
        try:
            self.core_api.delete_namespaced_config_map(
                name=configmap_name, namespace=self.namespace
            )
        except ApiException as e:
            if e.status != 404:
                raise

    def create_sandbox(
        self,
        thread_id: str,
        tenant_id: str = "local",
        team_id: str = "local",
        ttl_hours: int = 2,
        jwt_token: Optional[str] = None,
        team_token: Optional[str] = None,
    ) -> SandboxInfo:
        """
        Create a new sandbox for an investigation.

        The sandbox runs a FastAPI server on port 8888 that accepts /execute requests.
        Credentials are NOT injected into the sandbox - instead, HTTP requests are
        routed through an Envoy sidecar that injects auth headers via ext_authz.

        Args:
            thread_id: Unique identifier for the investigation thread
            tenant_id: Organization/tenant ID for credential lookup
            team_id: Team node ID for credential lookup
            ttl_hours: Hours until automatic cleanup (default: 2, balances resource usage and follow-up window)
            jwt_token: Pre-generated JWT for session reuse (if None, generates new one)
            team_token: Team token for config-driven agents (enables loading config from Config Service)

        Returns:
            SandboxInfo with details about the created sandbox
        """
        sandbox_name = f"investigation-{thread_id}"

        # Calculate shutdown time (TTL-based cleanup)
        shutdown_time = (datetime.utcnow() + timedelta(hours=ttl_hours)).strftime(
            "%Y-%m-%dT%H:%M:%SZ"
        )

        # Use provided JWT or generate new one
        if jwt_token is None:
            jwt_token = generate_sandbox_jwt(
                tenant_id=tenant_id,
                team_id=team_id,
                sandbox_name=sandbox_name,
                thread_id=thread_id,
                ttl_hours=ttl_hours + 1,  # JWT valid slightly longer than sandbox TTL
            )

        # Get credential-resolver namespace (used for both configmap and env vars)
        cred_resolver_ns = os.getenv(
            "CREDENTIAL_RESOLVER_NAMESPACE", "incidentfox-prod"
        )

        # Fetch configured integrations (non-sensitive metadata for system prompt)
        configured_integrations = fetch_configured_integrations(
            jwt_token, tenant_id, team_id
        )
        print(f"ðŸ“¦ Configured integrations for sandbox: {configured_integrations}")

        # Create per-sandbox ConfigMap with JWT embedded in Envoy config
        envoy_configmap_name = self._create_envoy_configmap(sandbox_name, jwt_token)

        sandbox_manifest = {
            "apiVersion": "agents.x-k8s.io/v1alpha1",
            "kind": "Sandbox",
            "metadata": {
                "name": sandbox_name,
                "namespace": self.namespace,
                "labels": {
                    "app": "incidentfox",
                    "thread-id": thread_id,
                    "managed-by": "incidentfox-server",
                },
            },
            "spec": {
                "podTemplate": {
                    "metadata": {
                        "labels": {
                            "app": "incidentfox-sandbox",  # Different from incidentfox-agent to avoid service routing
                            "thread-id": thread_id,
                        }
                    },
                    "spec": {
                        "containers": [
                            # Main agent container - NO SECRETS, only proxy config
                            {
                                "name": "agent",
                                "image": self.image,
                                "imagePullPolicy": (
                                    "Always"
                                    if "ecr" in self.image or "gcr" in self.image
                                    else "IfNotPresent"
                                ),
                                # FastAPI server runs automatically via CMD in Dockerfile
                                "ports": [{"containerPort": 8888, "name": "sandbox"}],
                                "env": [
                                    # Tenant context for credential lookup (no secrets!)
                                    {
                                        "name": "INCIDENTFOX_TENANT_ID",
                                        "value": tenant_id,
                                    },
                                    {
                                        "name": "INCIDENTFOX_TEAM_ID",
                                        "value": team_id,
                                    },
                                ]
                                # Config-driven agents: TEAM_TOKEN enables loading config from Config Service
                                + (
                                    [{"name": "TEAM_TOKEN", "value": team_token}]
                                    if team_token
                                    else []
                                )
                                + [
                                    # Claude SDK: route API requests through proxy
                                    # (proxy injects x-api-key header for Anthropic)
                                    {
                                        "name": "ANTHROPIC_BASE_URL",
                                        "value": "http://localhost:8001",
                                    },
                                    # Dummy API key - required by CLI but proxy injects real one
                                    {
                                        "name": "ANTHROPIC_API_KEY",
                                        "value": "sk-ant-placeholder-proxy-will-inject-real-key",
                                    },
                                    # LLM Provider configuration (multi-LLM support)
                                    # Set LLM_PROVIDER=openhands and LLM_MODEL to use Gemini/OpenAI
                                    {
                                        "name": "LLM_PROVIDER",
                                        "valueFrom": {
                                            "secretKeyRef": {
                                                "name": "incidentfox-secrets",
                                                "key": "llm-provider",
                                                "optional": True,  # Defaults to "claude" if not set
                                            }
                                        },
                                    },
                                    {
                                        "name": "LLM_MODEL",
                                        "valueFrom": {
                                            "secretKeyRef": {
                                                "name": "incidentfox-secrets",
                                                "key": "llm-model",
                                                "optional": True,  # Defaults to provider default
                                            }
                                        },
                                    },
                                    # Gemini API key (only needed if using LLM_MODEL=gemini/*)
                                    {
                                        "name": "GEMINI_API_KEY",
                                        "valueFrom": {
                                            "secretKeyRef": {
                                                "name": "incidentfox-secrets",
                                                "key": "gemini-api-key",
                                                "optional": True,
                                            }
                                        },
                                    },
                                    # OpenAI API key (only needed if using LLM_MODEL=openai/*)
                                    {
                                        "name": "OPENAI_API_KEY",
                                        "valueFrom": {
                                            "secretKeyRef": {
                                                "name": "incidentfox-secrets",
                                                "key": "openai-api-key",
                                                "optional": True,
                                            }
                                        },
                                    },
                                    # Coralogix SDK: route API requests through proxy
                                    # (proxy injects Authorization header for Coralogix)
                                    {
                                        "name": "CORALOGIX_BASE_URL",
                                        "value": "http://localhost:8001",
                                    },
                                    # Confluence SDK: route through credential-resolver's reverse proxy
                                    # (credential-resolver looks up URL + injects Basic auth)
                                    # Note: Confluence uses per-customer URLs (e.g., customer.atlassian.net)
                                    # so we can't use Envoy's static routing like Anthropic/Coralogix
                                    {
                                        "name": "CONFLUENCE_BASE_URL",
                                        "value": f"http://credential-resolver-svc.{cred_resolver_ns}.svc.cluster.local:8002/confluence",
                                    },
                                    # Additional integrations with customer-specific URLs
                                    # These all route through credential-resolver's reverse proxy
                                    {
                                        "name": "GRAFANA_BASE_URL",
                                        "value": f"http://credential-resolver-svc.{cred_resolver_ns}.svc.cluster.local:8002/grafana",
                                    },
                                    {
                                        "name": "ELASTICSEARCH_BASE_URL",
                                        "value": f"http://credential-resolver-svc.{cred_resolver_ns}.svc.cluster.local:8002/elasticsearch",
                                    },
                                    {
                                        "name": "PROMETHEUS_BASE_URL",
                                        "value": f"http://credential-resolver-svc.{cred_resolver_ns}.svc.cluster.local:8002/prometheus",
                                    },
                                    {
                                        "name": "JAEGER_BASE_URL",
                                        "value": f"http://credential-resolver-svc.{cred_resolver_ns}.svc.cluster.local:8002/jaeger",
                                    },
                                    {
                                        "name": "GITHUB_BASE_URL",
                                        "value": f"http://credential-resolver-svc.{cred_resolver_ns}.svc.cluster.local:8002/github",
                                    },
                                    {
                                        "name": "DATADOG_BASE_URL",
                                        "value": f"http://credential-resolver-svc.{cred_resolver_ns}.svc.cluster.local:8002/datadog",
                                    },
                                    # Configured integrations (non-sensitive metadata)
                                    # JSON list of {id, url?, domain?, region?} for each integration
                                    {
                                        "name": "CONFIGURED_INTEGRATIONS",
                                        "value": configured_integrations,
                                    },
                                    # Laminar tracing: platform observability (shared across all customers)
                                    # Used for debugging agent behavior - not customer data
                                    # NOTE: Temporarily disabled to debug proxy conflict issue
                                    {
                                        "name": "LMNR_PROJECT_API_KEY",
                                        "valueFrom": {
                                            "secretKeyRef": {
                                                "name": "incidentfox-secrets",
                                                "key": "laminar-api-key",
                                                "optional": True,
                                            }
                                        },
                                    },
                                    # Disable Laminar's claude-agent-sdk instrumentation
                                    # This prevents Laminar's proxy from intercepting Claude SDK calls
                                    # which may conflict with our Envoy sidecar credential injection
                                    {
                                        "name": "DISABLE_LAMINAR",
                                        "value": "true",
                                    },
                                    # Langfuse observability (optional)
                                    {
                                        "name": "LANGFUSE_PUBLIC_KEY",
                                        "valueFrom": {
                                            "secretKeyRef": {
                                                "name": "incidentfox-langfuse",
                                                "key": "LANGFUSE_PUBLIC_KEY",
                                                "optional": True,
                                            }
                                        },
                                    },
                                    {
                                        "name": "LANGFUSE_SECRET_KEY",
                                        "valueFrom": {
                                            "secretKeyRef": {
                                                "name": "incidentfox-langfuse",
                                                "key": "LANGFUSE_SECRET_KEY",
                                                "optional": True,
                                            }
                                        },
                                    },
                                    {
                                        "name": "LANGFUSE_HOST",
                                        "value": os.getenv(
                                            "LANGFUSE_HOST",
                                            "https://us.cloud.langfuse.com",
                                        ),
                                    },
                                    # Kubernetes context (use pre-configured kubeconfig for incidentfox-demo cluster)
                                    {
                                        "name": "KUBECONFIG",
                                        "value": "/home/agent/.kube/config",
                                    },
                                    # Dynamic values
                                    {"name": "THREAD_ID", "value": thread_id},
                                    {"name": "SANDBOX_NAME", "value": sandbox_name},
                                    {"name": "NAMESPACE", "value": self.namespace},
                                    # JWT for authenticating with credential-resolver
                                    # (used by scripts that call credential-resolver directly)
                                    {"name": "SANDBOX_JWT", "value": jwt_token},
                                ],
                                "resources": {
                                    "requests": {
                                        "memory": "512Mi",
                                        "cpu": "100m",  # Low: agents are I/O-bound (Claude API calls)
                                        "ephemeral-storage": "2Gi",
                                    },
                                    "limits": {
                                        "memory": "2Gi",
                                        "cpu": "2000m",  # High: allows bursts for git/file ops
                                        "ephemeral-storage": "10Gi",  # Large for file attachments
                                    },
                                },
                                "securityContext": {
                                    "allowPrivilegeEscalation": False,
                                    "runAsNonRoot": True,
                                    "runAsUser": 1000,
                                    "capabilities": {"drop": ["ALL"]},
                                },
                                # Startup probe: allows time for FastAPI server initialization
                                # Prevents traffic routing before server is ready
                                "startupProbe": {
                                    "httpGet": {
                                        "path": "/health",
                                        "port": 8888,
                                    },
                                    "initialDelaySeconds": 2,
                                    "periodSeconds": 2,
                                    "timeoutSeconds": 3,
                                    "failureThreshold": 15,  # 2 + (15 * 2) = 32s max startup
                                },
                                # Readiness probe: signals when pod can receive traffic
                                "readinessProbe": {
                                    "httpGet": {
                                        "path": "/health",
                                        "port": 8888,
                                    },
                                    "initialDelaySeconds": 3,
                                    "periodSeconds": 5,
                                    "timeoutSeconds": 3,
                                    "failureThreshold": 2,
                                },
                            },
                            # Envoy sidecar - handles credential injection via ext_authz
                            {
                                "name": "envoy",
                                "image": "envoyproxy/envoy:v1.28-latest",
                                "args": [
                                    "--config-path",
                                    "/etc/envoy/envoy.yaml",
                                    "--log-level",
                                    "warn",
                                ],
                                "ports": [{"containerPort": 8001, "name": "proxy"}],
                                "volumeMounts": [
                                    {
                                        "name": "envoy-config",
                                        "mountPath": "/etc/envoy",
                                        "readOnly": True,
                                    }
                                ],
                                "resources": {
                                    "requests": {"cpu": "50m", "memory": "64Mi"},
                                    "limits": {"cpu": "200m", "memory": "128Mi"},
                                },
                                "securityContext": {
                                    "runAsNonRoot": True,
                                    "runAsUser": 1000,
                                    "allowPrivilegeEscalation": False,
                                },
                            },
                        ],
                        "volumes": [
                            {
                                "name": "envoy-config",
                                "configMap": {"name": envoy_configmap_name},
                            }
                        ],
                    },
                },
                # Automatic cleanup after TTL (shutdownTime is a top-level spec field)
                "shutdownTime": shutdown_time,
                "replicas": 1,
            },
        }

        # Add gVisor runtime for production (optional for local dev)
        if os.getenv("USE_GVISOR", "false").lower() == "true":
            sandbox_manifest["spec"]["podTemplate"]["spec"][
                "runtimeClassName"
            ] = "gvisor"

        try:
            self.custom_api.create_namespaced_custom_object(
                group="agents.x-k8s.io",
                version="v1alpha1",
                namespace=self.namespace,
                plural="sandboxes",
                body=sandbox_manifest,
            )

            return SandboxInfo(
                name=sandbox_name,
                thread_id=thread_id,
                created_at=datetime.utcnow(),
                namespace=self.namespace,
            )
        except ApiException as e:
            raise Exception(f"Failed to create sandbox: {e}")

    def get_sandbox(self, thread_id: str) -> Optional[SandboxInfo]:
        """Get sandbox info for a thread. Returns info if sandbox exists."""
        sandbox_name = f"investigation-{thread_id}"

        try:
            sandbox = self.custom_api.get_namespaced_custom_object(
                group="agents.x-k8s.io",
                version="v1alpha1",
                namespace=self.namespace,
                plural="sandboxes",
                name=sandbox_name,
            )

            created = sandbox.get("metadata", {}).get("creationTimestamp")

            return SandboxInfo(
                name=sandbox_name,
                thread_id=thread_id,
                created_at=(
                    datetime.fromisoformat(created.replace("Z", "+00:00"))
                    if created
                    else datetime.utcnow()
                ),
                namespace=self.namespace,
            )
        except ApiException as e:
            if e.status == 404:
                return None
            raise

    def delete_sandbox(self, thread_id: str):
        """Delete a sandbox and clean up associated resources (ConfigMap)."""
        sandbox_name = f"investigation-{thread_id}"

        # Delete the sandbox custom resource
        try:
            self.custom_api.delete_namespaced_custom_object(
                group="agents.x-k8s.io",
                version="v1alpha1",
                namespace=self.namespace,
                plural="sandboxes",
                name=sandbox_name,
            )
        except ApiException as e:
            if e.status != 404:
                raise

        # Clean up per-sandbox Envoy ConfigMap
        self._delete_envoy_configmap(sandbox_name)

    def wait_for_ready(self, thread_id: str, timeout: int = 120) -> bool:
        """
        Wait for sandbox pod to be ready and FastAPI server to be responding.

        Args:
            thread_id: Investigation thread ID
            timeout: Max wait time in seconds

        Returns:
            True if ready, False if timeout
        """
        start_time = time.time()
        sandbox_name = f"investigation-{thread_id}"

        while time.time() - start_time < timeout:
            try:
                # Get pods for this sandbox
                pods = self.core_api.list_namespaced_pod(
                    namespace=self.namespace, label_selector=f"thread-id={thread_id}"
                )

                if not pods.items:
                    time.sleep(2)
                    continue

                pod = pods.items[0]

                # Check if pod is ready
                if pod.status.phase == "Running":
                    for condition in pod.status.conditions or []:
                        if condition.type == "Ready" and condition.status == "True":
                            # Pod is K8s Ready, now verify FastAPI server is responding
                            # via the sandbox-router (same path as execute_in_sandbox)
                            try:
                                router_url = self.get_router_url()
                                health_response = requests.get(
                                    f"{router_url}/health",
                                    headers={
                                        "X-Sandbox-ID": sandbox_name,
                                        "X-Sandbox-Port": "8888",
                                        "X-Sandbox-Namespace": self.namespace,
                                    },
                                    timeout=5,
                                )
                                if health_response.status_code == 200:
                                    print(
                                        f"âœ… Sandbox {sandbox_name} health check passed"
                                    )
                                    # Small buffer to let server fully warm up
                                    time.sleep(0.5)
                                    return True
                                else:
                                    print(
                                        f"â³ Sandbox health check returned {health_response.status_code}, retrying..."
                                    )
                            except requests.RequestException as e:
                                print(
                                    f"â³ Sandbox health check failed ({e}), retrying..."
                                )

            except ApiException:
                pass

            time.sleep(2)

        return False

    def get_router_url(self) -> str:
        """
        Get the Router URL for sandbox communication.

        Returns http://sandbox-router-svc.<namespace>.svc.cluster.local:8080 for in-cluster,
        or http://localhost:8080 if ROUTER_LOCAL_PORT env var is set for development.
        """
        local_port = os.getenv("ROUTER_LOCAL_PORT")
        if local_port:
            return f"http://localhost:{local_port}"
        # Router is deployed in incidentfox-prod namespace, sandboxes in default
        router_namespace = os.getenv("ROUTER_NAMESPACE", "incidentfox-prod")
        return f"http://sandbox-router-svc.{router_namespace}.svc.cluster.local:8080"

    def execute_in_sandbox(
        self,
        sandbox_info: SandboxInfo,
        prompt: str,
        images: list = None,
        file_downloads: list = None,
    ) -> requests.Response:
        """
        Execute an investigation in the sandbox via the Sandbox Router (streaming).

        This returns a streaming response that yields chunks as they arrive,
        enabling real-time display of agent output.

        Args:
            sandbox_info: Sandbox information
            prompt: Investigation prompt
            images: Optional list of image dicts (type, media_type, data, filename)
            file_downloads: Optional list of file download info for sandbox to fetch via proxy
                           Each dict has: {token, filename, size, media_type, proxy_url}

        Returns:
            requests.Response object with stream=True

        Raises:
            SandboxExecutionError: If the request to the sandbox fails
        """
        router_url = self.get_router_url()

        headers = {
            "X-Sandbox-ID": sandbox_info.name,
            "X-Sandbox-Port": "8888",
            "X-Sandbox-Namespace": self.namespace,
        }

        payload = {"prompt": prompt, "thread_id": sandbox_info.thread_id}

        if images:
            payload["images"] = images

        if file_downloads:
            payload["file_downloads"] = file_downloads

        try:
            # For streaming SSE, use tuple timeout: (connect_timeout, read_timeout)
            # connect_timeout: 30s to establish connection
            # read_timeout: None - no timeout between SSE events (agent may think for minutes)
            response = requests.post(
                f"{router_url}/execute",
                headers=headers,
                json=payload,
                stream=True,
                timeout=(30, None),  # (connect, read) - no read timeout for streaming
            )
            response.raise_for_status()
            return response
        except requests.RequestException as e:
            raise SandboxExecutionError(
                f"Failed to execute in sandbox via Router: {e}"
            ) from e

    def interrupt_sandbox(self, sandbox_info: SandboxInfo) -> requests.Response:
        """
        Interrupt the current execution in the sandbox (streaming).

        This allows users to stop a long-running task mid-execution.
        After interrupt, new messages should be sent via the normal /investigate endpoint.

        The Router uses the same headers as execute_in_sandbox but calls the
        /interrupt endpoint instead.

        Args:
            sandbox_info: Sandbox information

        Returns:
            requests.Response object (streaming)

        Raises:
            SandboxInterruptError: If the interrupt request fails

        Note: This follows Cursor's UX - interrupt just stops, new messages
        are queued separately.
        """
        router_url = self.get_router_url()

        headers = {
            "X-Sandbox-ID": sandbox_info.name,
            "X-Sandbox-Port": "8888",
            "X-Sandbox-Namespace": self.namespace,
        }

        payload = {"thread_id": sandbox_info.thread_id}

        try:
            # Same streaming timeout pattern as execute_in_sandbox
            response = requests.post(
                f"{router_url}/interrupt",
                headers=headers,
                json=payload,
                stream=True,
                timeout=(30, None),  # (connect, read) - no read timeout for streaming
            )
            response.raise_for_status()
            return response
        except requests.RequestException as e:
            raise SandboxInterruptError(
                f"Failed to interrupt sandbox via Router: {e}"
            ) from e

    def send_answer_to_sandbox(self, sandbox_info: SandboxInfo, answers: dict) -> dict:
        """
        Send answer to AskUserQuestion to the sandbox via the Router.

        Args:
            sandbox_info: Sandbox information
            answers: User's answers to the questions

        Returns:
            Response from sandbox

        Raises:
            SandboxExecutionError: If the request fails
        """
        router_url = self.get_router_url()

        headers = {
            "X-Sandbox-ID": sandbox_info.name,
            "X-Sandbox-Port": "8888",
            "X-Sandbox-Namespace": self.namespace,
        }

        payload = {"thread_id": sandbox_info.thread_id, "answers": answers}

        try:
            response = requests.post(
                f"{router_url}/answer", headers=headers, json=payload, timeout=10
            )
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            raise SandboxExecutionError(
                f"Failed to send answer to sandbox via Router: {e}"
            ) from e
